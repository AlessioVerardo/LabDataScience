{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1d1081-0a88-4da8-842c-252956c32073",
   "metadata": {},
   "source": [
    "# Merge graph components\n",
    "\n",
    "In this notebook, we build the graph that will be the basis of our journey planner algorithm.\n",
    "\n",
    "## Setup PySpark\n",
    "We first start by loading the Spark session. Note that some of our queries are heavy and this notebook should be run only once, we allow ourselves take a bit more resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da683fdf-6103-4732-953b-d6079046b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8305cd20-3405-47d1-bd08-4ffb28a36136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpittet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "username = os.environ['RENKU_USERNAME']\n",
    "print(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281983b4-fd9a-457d-9f59-9f2a182d30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"http://iccluster029.iccluster.epfl.ch:8998\"\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_cell_magic('spark', line=\"config\",\n",
    "                             cell=\"\"\"{{ \"name\":\"{0}-aces\", \"executorMemory\":\"10G\", \"executorCores\":8, \"numExecutors\":10 }}\"\"\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b108e8-3631-41c8-836e-0e6a78fd2e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>9453</td><td>application_1652960972356_5285</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster029.iccluster.epfl.ch:8088/proxy/application_1652960972356_5285/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster059.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1652960972356_5285_01_000001/eric\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "get_ipython().run_line_magic(\n",
    "    \"spark\", \"add -s {0}-aces -l python -u {1} -k\".format(username, server) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe87956-ae26-46a8-a963-1f4c370684b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065aeae-7804-4b80-b530-c2ec52105352",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The first part is to merge the preprocessed with istdaten to have delay information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "258ceeb6-79cf-4ac4-8ec0-4f7ccac753a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "# Read the delay dataframe contained the stop delay estimation\n",
    "istdaten_delays = spark.read.orc('/group/aces/istdaten_delays.orc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec863d18-e2f5-45fe-92a5-9286102f4a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23898"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "istdaten_delays.count() # Number of stop delay estimation 38_641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72bbab8b-3338-4bf1-bc86-6cd49c537449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "@F.udf\n",
    "def extract_stop_id(x):\n",
    "    \"\"\"\n",
    "    Extract stop id from full stop id\n",
    "    \"\"\"\n",
    "    return x.split('_')[0]\n",
    "\n",
    "# Load the transport edges and set join on their correct bpuic, hour and transport to get the average delay for this stop\n",
    "stop_times_zh_pairs = spark.read.orc(\"/group/aces/graph/edges_transport_final.orc\")\n",
    "stop_times_zh_delay = stop_times_zh_pairs.withColumn('end_bpuic', extract_stop_id(col('end_id')))\n",
    "\n",
    "stop_times_zh_delay = stop_times_zh_delay.join(istdaten_delays, how='left', on=['end_bpuic', 'transport', 'hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4679ae2e-5f79-463e-87cf-6df553d56c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(transport=u'Other'), Row(transport=u'Tram'), Row(transport=u'Bus'), Row(transport=u'Train')]"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "# get all the transport types\n",
    "stop_times_zh_delay.select('transport').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "022afdc8-0000-4079-ab0a-39f143663d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "# Impute missing delay values with avg for this kind of transport and that hour\n",
    "# Computet the mean_delay, std_delay, median_delay for each transport type and each hour\n",
    "avg_delays_by_transport = [row.asDict() for row in stop_times_zh_delay.groupBy(['transport', 'hour']).agg(\n",
    "        F.expr('mean(mean_delay)').alias('mean_delay'),\n",
    "        F.expr('std(mean_delay)').alias('std_delay'),\n",
    "        F.expr('percentile(mean_delay,array(0.5))')[0].alias('median_delay')\n",
    "    ).collect()]\n",
    "# Collect all of this in a dictionnary\n",
    "avg_delays_by_transport = {(d['transport'], d['hour']): {\"mean_delay\":d['mean_delay'],\"std_delay\":d['std_delay'], \"median_delay\":d['median_delay']} for d in avg_delays_by_transport}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "146c5baf-ddf8-44df-973f-6a8d13483e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "@F.udf\n",
    "def impute_missing_mean(transport, hour):\n",
    "    \"\"\"\n",
    "    Get the mean delay for the given (transport, hour) air\n",
    "    :param transport: the transport mean we want to input the mean delay\n",
    "    :param hour: the transport hour we want to input the mean delay\n",
    "    :return: the corresponding mean delay\n",
    "    \"\"\"\n",
    "    return avg_delays_by_transport[(transport, hour)][\"mean_delay\"]\n",
    "\n",
    "@F.udf\n",
    "def impute_missing_std(transport, hour):\n",
    "    \"\"\"\n",
    "    Get the std delay for the given (transport, hour) air\n",
    "    :param transport: the transport mean we want to input the std delay\n",
    "    :param hour: the transport hour we want to input the std delay\n",
    "    :return: the corresponding std delay\n",
    "    \"\"\"\n",
    "    return avg_delays_by_transport[(transport, hour)][\"std_delay\"]\n",
    "\n",
    "@F.udf\n",
    "def impute_missing_median(transport, hour):\n",
    "    \"\"\"\n",
    "    Get the median delay for the given (transport, hour) air\n",
    "    :param transport: the transport mean we want to input the median delay\n",
    "    :param hour: the transport hour we want to input the median delay\n",
    "    :return: the corresponding median delay\n",
    "    \"\"\"\n",
    "    return avg_delays_by_transport[(transport, hour)][\"median_delay\"]\n",
    "\n",
    "# infer the missing delay by putting the average delay, std and median for this transport type at this hour\n",
    "stop_times_zh_delay = stop_times_zh_delay.withColumn('mean_delay', when(col('mean_delay').isNotNull(), col('mean_delay')).otherwise(impute_missing_mean(col('transport'), col('hour'))))\n",
    "stop_times_zh_delay = stop_times_zh_delay.withColumn('std_delay', when(col('std_delay').isNotNull(), col('std_delay')).otherwise(impute_missing_std(col('transport'), col('hour'))))\n",
    "stop_times_zh_delay = stop_times_zh_delay.withColumn('median_delay', when(col('median_delay').isNotNull(), col('median_delay')).otherwise(impute_missing_median(col('transport'), col('hour'))))\n",
    "stop_times_zh_delay = stop_times_zh_delay.drop('avg_delay')\n",
    "\n",
    "# Put columns in right order for the union (the union is NOT made by name only by column position)\n",
    "stop_times_zh_delay = stop_times_zh_delay.select(\n",
    "    stop_times_zh_delay.start_id,\n",
    "    stop_times_zh_delay.end_id,\n",
    "    stop_times_zh_delay.mean_delay,\n",
    "    stop_times_zh_delay.std_delay,\n",
    "    stop_times_zh_delay.median_delay,\n",
    "    stop_times_zh_delay.duration,\n",
    "    stop_times_zh_delay.transport,\n",
    "    stop_times_zh_delay.line_number,\n",
    "    stop_times_zh_delay.is_trip,\n",
    "    stop_times_zh_delay.waiting_time,\n",
    "    stop_times_zh_delay.hour\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e73121b-6e64-4d05-8944-87d618ee3d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark \n",
    "# Merge all types of edges into one dataframe\n",
    "# Reread all files from hdfs\n",
    "all_walking_edges = spark.read.orc('/group/aces/graph/all_walking_edges_final.orc')\n",
    "all_same_station_edges = spark.read.orc('/group/aces/graph/all_same_station_edges_final.orc')\n",
    "nodes_zurich = spark.read.orc(\"/group/aces/graph/nodes_final.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f1d05b-a76e-4f1e-ada5-c568e4dff70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "# Get the avg delay by full stop id as a dictionnary since Spark cannot do the join itself without crashing\n",
    "\n",
    "avg_delay_by_full_stop_id = [row.asDict() for row in stop_times_zh_delay.select(col(\"end_id\").alias(\"start_id\"), col(\"mean_delay\")).collect()]\n",
    "dic_avg_delay_by_full_stop_id = {d['start_id']:d['mean_delay'] for d in avg_delay_by_full_stop_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3607236-7a51-4c0c-9b7a-baa6f7527401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "@F.udf\n",
    "def impute_missing_mean_delay(stop_id, line_number):\n",
    "    \"\"\"\n",
    "    :param stop_id: the stop id of the stop\n",
    "    :param line_number: the line number of the stop or -1 if it is a walking edge between two lines.\n",
    "    :return: \n",
    "        - the avg delay by full stop id if the line number is -1 and the stop id is know\n",
    "        - 0 otherwise\n",
    "    \"\"\"\n",
    "    if line_number == \"-1\":\n",
    "        if stop_id in dic_avg_delay_by_full_stop_id:\n",
    "            return dic_avg_delay_by_full_stop_id[stop_id]\n",
    "        else:\n",
    "            return 0.0\n",
    "    else:\n",
    "        return 0.0\n",
    "# Impute the missing delay information\n",
    "all_same_station_edges_wt_delay = all_same_station_edges.withColumn(\"mean_delay\", impute_missing_mean_delay(col(\"start_id\"),col(\"line_number\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffcb8295-49c7-464c-8890-b03f7e33e58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "# Make the union of all the edges\n",
    "all_edges = all_walking_edges.union(all_same_station_edges_wt_delay).union(stop_times_zh_delay).filter(col(\"mean_delay\").isNotNull())\n",
    "# Cast the important columns as float for the saving on HDFS\n",
    "all_edges = all_edges.withColumn('mean_delay', col('mean_delay').cast(FloatType()))\n",
    "all_edges = all_edges.withColumn('std_delay', col('std_delay').cast(FloatType()))\n",
    "all_edges = all_edges.withColumn('median_delay', col('median_delay').cast(FloatType()))\n",
    "# Compute 2 different edge weights to be used in shortest path\n",
    "all_edges = all_edges.withColumn(\"edge_weight\", col('waiting_time')+col('duration'))\n",
    "all_edges = all_edges.withColumn(\"edge_weight_wt_mean_delay\", when(col(\"edge_weight\")+col(\"mean_delay\") > 0 ,col(\"edge_weight\")+col(\"mean_delay\")).otherwise(0.0))\n",
    "all_edges = all_edges.withColumn(\"std_delay\", when(col(\"edge_weight\")+col(\"mean_delay\") > 0 ,col(\"std_delay\")+col(\"mean_delay\")).otherwise(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9d71ba9-ae8b-4cf9-a4dd-87808eaaf5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "# Write the final dataframe on HDFS\n",
    "all_edges.write.save(\"/group/aces/graph/all_edges_final.orc\", format=\"orc\", mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
